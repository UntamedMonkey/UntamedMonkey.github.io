<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        pytorch使用总结 - undefined
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.4.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 舟を漕いで、濡れながら </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/favicon.ico" />
        </div>
        <div class="name">
            <i></i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#dataloader"><span class="toc-text">dataloader</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#dataloader-1"><span class="toc-text">dataloader</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#moudle"><span class="toc-text">moudle</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#optimizer"><span class="toc-text">optimizer</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gradient-descent"><span class="toc-text">gradient descent</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 舟を漕いで、濡れながら </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        pytorch使用总结
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2023-01-30 18:08:03</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#学习笔记" title="学习笔记">学习笔记</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#pytorch" title="pytorch">pytorch</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p>运行：<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1rd-EoeB5iBu55VicbBZYMWp5xxA63VMi#scrollTo=yzA0_qm16zhb">colab notebook</a></p>
<ol>
<li>tensor赋值、常用方法</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy转换</span></span><br><span class="line">a = np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">y = (torch.tensor(a, dtype=torch.float32, </span><br><span class="line">                  requires_grad=<span class="literal">False</span>, device=<span class="string">&#x27;cuda:0&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y=&quot;</span>, y)</span><br><span class="line">an = y.cpu().numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;an=&quot;</span>, an)</span><br><span class="line"></span><br><span class="line"><span class="comment"># list转换</span></span><br><span class="line">b = [[<span class="number">4</span> * i + j <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">z = (torch.tensor(b, dtype=torch.float32, </span><br><span class="line">                  requires_grad=<span class="literal">False</span>, device=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;z=&quot;</span>, z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机初始化</span></span><br><span class="line">u = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;u=&quot;</span>, u)</span><br><span class="line">v = torch.randn_like(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;v=&quot;</span>, v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常用方法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y.size:&quot;</span>, y.size())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y.view:&quot;</span>, y.view(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; output:</span></span><br><span class="line"><span class="string">y= tensor([[0., 1., 2., 3.],</span></span><br><span class="line"><span class="string">        [4., 5., 6., 7.]], device=&#x27;cuda:0&#x27;)</span></span><br><span class="line"><span class="string">an= [[0. 1. 2. 3.]</span></span><br><span class="line"><span class="string"> [4. 5. 6. 7.]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">z= tensor([[0., 1., 2., 3.],</span></span><br><span class="line"><span class="string">        [4., 5., 6., 7.]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">u= tensor([[0.3741, 0.0632, 0.7546],</span></span><br><span class="line"><span class="string">        [0.9163, 0.8642, 0.2626]])</span></span><br><span class="line"><span class="string">v= tensor([[-0.1389, -0.0200, -0.7156, -0.4071],</span></span><br><span class="line"><span class="string">        [-0.0301, -0.3345,  0.4790,  0.1603]], device=&#x27;cuda:0&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y.size: torch.Size([2, 4])</span></span><br><span class="line"><span class="string">y.view: tensor([0., 1., 2., 3., 4., 5., 6., 7.], device=&#x27;cuda:0&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>


<ol start="2">
<li>利用底层autograd实现linear regression<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 训练数据</span></span><br><span class="line">gt_w = (torch.tensor(np.array([[<span class="number">6</span>, -<span class="number">0.6</span>, <span class="number">0.06</span>]]).T, </span><br><span class="line">                device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.float32))</span><br><span class="line">gt_b = <span class="number">6.6</span></span><br><span class="line">x = torch.rand(<span class="number">1000</span>, <span class="number">3</span>).cuda()</span><br><span class="line">y = torch.mm(x, gt_w) + gt_b</span><br><span class="line">y = y + torch.rand_like(y) * <span class="number">10e-3</span></span><br><span class="line"><span class="comment"># 线性模型的参数</span></span><br><span class="line">w = torch.rand(<span class="number">3</span>, <span class="number">1</span>, requires_grad=<span class="literal">True</span>, device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">b = torch.rand(<span class="number">1</span>, <span class="number">1</span>, requires_grad=<span class="literal">True</span>, device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">  pred = torch.mm(x, w) + b</span><br><span class="line">  loss = torch.mean((pred-y)*(pred-y))</span><br><span class="line">  <span class="keyword">if</span> i%<span class="number">100</span>==<span class="number">99</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;i&#125;th iter loss:&quot;</span>.<span class="built_in">format</span>(i=i).ljust(<span class="number">18</span>), loss.item())</span><br><span class="line">  <span class="comment"># 计算各节点梯度</span></span><br><span class="line">  loss.backward()</span><br><span class="line">  <span class="keyword">if</span> loss.item()&lt;<span class="number">10e-6</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;final w.grad&quot;</span>, w.grad.cpu().detach().numpy().T[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">  <span class="comment"># w,b在此处的计算不能构图，否则会循环 </span></span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    w-=<span class="number">0.25</span> * w.grad</span><br><span class="line">    b-=<span class="number">0.25</span> * b.grad</span><br><span class="line">    <span class="comment"># 每次梯度下降后要置零</span></span><br><span class="line">    w.grad.zero_()</span><br><span class="line">    b.grad.zero_()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gt w =&quot;</span>, gt_w.cpu().detach().numpy().T[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gt b =&quot;</span>, gt_b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;learned w =&quot;</span>, w.cpu().detach().numpy().T[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;learned b =&quot;</span>, b.cpu().detach().numpy()[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;output</span></span><br><span class="line"><span class="string">99th iter loss:    0.0023212977685034275</span></span><br><span class="line"><span class="string">199th iter loss:   2.7834581487695687e-05</span></span><br><span class="line"><span class="string">final w.grad [0.00022115 0.00025191 0.00026335]</span></span><br><span class="line"><span class="string">gt w = [ 6.   -0.6   0.06]</span></span><br><span class="line"><span class="string">gt b = 6.6</span></span><br><span class="line"><span class="string">learned w = [ 6.0024757  -0.59749424  0.06294169]</span></span><br><span class="line"><span class="string">learned b = 6.6008897</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
用torch的module、optimizer、dataloader重构上面的lr模型<br>```python<br>import torch<br>import numpy as np<br>from torch.utils.data import TensorDataset, DataLoader<h1 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h1>gt_w = (torch.tensor(np.array([[6, -0.6, 0.06]]).T, <pre><code>         device=&#39;cpu&#39;, dtype=torch.float32))
</code></pre>
gt_b = 6.6<br>x = torch.rand(1000, 3)<br>y = torch.mm(x, gt_w) + gt_b<br>y = y + torch.rand_like(y) * 10e-3<h1 id="dataloader-1"><a href="#dataloader-1" class="headerlink" title="dataloader"></a>dataloader</h1>data = TensorDataset(x, y)<br>data_batch = DataLoader(data, batch_size=1000, shuffle=True)<h1 id="moudle"><a href="#moudle" class="headerlink" title="moudle"></a>moudle</h1>model = torch.nn.Linear(3, 1)<h1 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h1>loss_fn = torch.nn.functional.mse_loss<br>optim = torch.optim.Adam(model.parameters(), lr=0.9)<h1 id="gradient-descent"><a href="#gradient-descent" class="headerlink" title="gradient descent"></a>gradient descent</h1>for i in range(10000):<br>for x_batch, y_batch in data_batch:<br> pred = model(x_batch)<br> loss = loss_fn(pred, y_batch)<br> loss.backward()<br> optim.step()<br> optim.zero_grad()<br>if i%100==99:<br> print(“{i}th iter loss:”.format(i=i).ljust(18), loss.item())<br>if loss.item()&lt;10e-6:<br> break<br>print(“gt w =”, gt_w.detach().numpy().T[0])<br>print(“gt b =”, gt_b)<br>print(“learned w =”, model.weight.detach().numpy().T)<br>print(“learned b =”, model.bias.detach().numpy())</li>
</ol>
<p>“””output<br>99th iter loss:    0.005614231340587139<br>gt w = [ 6.   -0.6   0.06]<br>gt b = 6.6<br>learned w = [[ 6.0015745 ]<br> [-0.6000941 ]<br> [ 0.05913432]]<br>learned b = [6.602816]<br>“””</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
